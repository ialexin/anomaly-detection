{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import funcy\n",
    "import json\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "from lib.Autoencoder import Autoencoder\n",
    "from lib.DatasetLoader import DatasetLoader\n",
    "from lib.helpers.TimeLogger import TimeLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_percent = 0.9\n",
    "encoding_dim_percent = 0.5\n",
    "use_dbscan = None\n",
    "output_file = 'anomalies_results/differences.json'\n",
    "files_map_file = 'dataset/files_map.json'\n",
    "anomalies_output_file = 'anomalies_results/anomalies.json'\n",
    "dataset_file = 'dataset/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascii_read(differences_file):\n",
    "    differences_read_logger = TimeLogger(task_name='Differences read')\n",
    "    with open(differences_file) as f:\n",
    "        differences = json.loads(f.read())\n",
    "\n",
    "        difference_indexes = []\n",
    "        difference_values = []\n",
    "        for difference in differences:\n",
    "            difference_indexes.append(difference[0])\n",
    "            difference_values.append(difference[1])\n",
    "\n",
    "    differences_read_logger.finish()\n",
    "\n",
    "    return difference_indexes, difference_values\n",
    "\n",
    "def ascii_write(output_file, differences):\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(json.dumps(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviation_anomaly_selection(differences, sigma_deviation_bound=3):\n",
    "    time_logger = TimeLogger('%s-sigma anomaly selection' % sigma_deviation_bound)\n",
    "\n",
    "    difference_indexes, difference_values = differences\n",
    "    mean = np.mean(difference_values)\n",
    "    std_deviation = np.std(difference_values)\n",
    "    left_bound_deviation = mean - sigma_deviation_bound * std_deviation\n",
    "    right_bound_deviation = mean + sigma_deviation_bound * std_deviation\n",
    "\n",
    "    anomalies = []\n",
    "    for i, x in enumerate(difference_values):\n",
    "        if x < left_bound_deviation or x > right_bound_deviation:\n",
    "            anomalies.append((difference_indexes[i], difference_values[i]))\n",
    "\n",
    "    time_logger.finish()\n",
    "\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DatasetLoader(dataset_file).load(split_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "2568\n"
     ]
    }
   ],
   "source": [
    "(_, _, features_number) = data\n",
    "print(type(data))\n",
    "print(features_number)\n",
    "encoding_dim = math.ceil(features_number * encoding_dim_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Autoencoder fit\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1284)              3298596   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2568)              3299880   \n",
      "=================================================================\n",
      "Total params: 6,598,476\n",
      "Trainable params: 6,598,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1490 samples, validate on 14901 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.7094 - val_loss: 0.7010\n",
      "Epoch 2/5\n",
      " - 5s - loss: 0.6939 - val_loss: 0.6964\n",
      "Epoch 3/5\n",
      " - 5s - loss: 0.6834 - val_loss: 0.6922\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.6744 - val_loss: 0.6887\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.6667 - val_loss: 0.6852\n",
      "Autoencoder fit finished. Time: 0:00:29.061000\n"
     ]
    }
   ],
   "source": [
    "time_logger = TimeLogger(task_name='Autoencoder fit')\n",
    "autoencoder = Autoencoder(features_number, encoding_dim, data)\n",
    "autoencoder.print_model_summary()\n",
    "autoencoder.fit()\n",
    "time_logger.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Autoencoder predict\n",
      "Autoencoder predict finished. Time: 0:00:07.551000\n"
     ]
    }
   ],
   "source": [
    "time_logger = TimeLogger(task_name='Autoencoder predict')\n",
    "autoencoder.predict()\n",
    "time_logger.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Calculate differences\n",
      "Calculate differences finished. Time: 0:00:00.854000\n"
     ]
    }
   ],
   "source": [
    "time_logger = TimeLogger(task_name='Calculate differences')\n",
    "differences = autoencoder.calc_differences(full_differences=use_dbscan)\n",
    "time_logger.finish()\n",
    "\n",
    "if not use_dbscan:\n",
    "    differences = sorted(enumerate(differences), key=lambda tup: tup[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascii_write(output_file, differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Differences read\n",
      "Differences read finished. Time: 0:00:00.080000\n",
      "Start 3-sigma anomaly selection\n",
      "3-sigma anomaly selection finished. Time: 0:00:00.021000\n",
      "Start Anomaly list write\n",
      "Anomaly list write finished. Time: 0:00:00.098000\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "differences = ascii_read(output_file)\n",
    "anomalies = deviation_anomaly_selection(differences)\n",
    "\n",
    "anomalies_write_time_logger = TimeLogger('Anomaly list write')\n",
    "with open(files_map_file) as files_map_file_descriptor:\n",
    "    files_map = json.loads(files_map_file_descriptor.read())\n",
    "    anomaly_files = []\n",
    "    for anomaly_index, anomaly_value in anomalies:\n",
    "        anomaly_files.append((files_map[anomaly_index], anomaly_value))\n",
    "\n",
    "    with open(anomalies_output_file, 'w') as anomalies_output_file_descriptor:\n",
    "        anomalies_output_file_descriptor.write(json.dumps(anomaly_files))\n",
    "\n",
    "anomalies_write_time_logger.finish()\n",
    "\n",
    "print(len(anomaly_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
